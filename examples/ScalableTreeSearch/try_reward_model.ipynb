{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/shibo/anaconda3/envs/sgl-py310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/data/shibo/anaconda3/envs/sgl-py310/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import ast\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import sglang as sgl\n",
    "from sglang.test.test_utils import (\n",
    "    add_common_sglang_args_and_parse,\n",
    "    select_sglang_backend,\n",
    ")\n",
    "from sglang.utils import dump_state_text, read_jsonl\n",
    "\n",
    "INVALID = -9999999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = argparse.Namespace(\n",
    "    data_path=\"sglang/benchmark/tree_of_thought_v0/test.jsonl\",\n",
    "    num_questions=2,\n",
    "    port=10086,\n",
    "    parallel=4,\n",
    "    backend='srt',\n",
    "    host=\"http://127.0.0.1\",\n",
    "    result_file=\"results.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_answer_value(answer_str):\n",
    "    answer_str = answer_str.replace(\",\", \"\")\n",
    "    numbers = re.findall(r\"\\d+\", answer_str)\n",
    "    if len(numbers) < 1:\n",
    "        return INVALID\n",
    "    try:\n",
    "        return ast.literal_eval(numbers[-1])\n",
    "    except SyntaxError:\n",
    "        return INVALID\n",
    "\n",
    "\n",
    "def most_frequent_number(numbers):\n",
    "    if not numbers:\n",
    "        return None\n",
    "\n",
    "    frequency = Counter(numbers)\n",
    "    most_frequent = max(frequency, key=frequency.get)\n",
    "    return most_frequent\n",
    "\n",
    "\n",
    "# Use a low temp to make the results more deterministic and the comparison more fair.\n",
    "temp = 0.001\n",
    "\n",
    "\n",
    "def propose_plan(s, question, num_branches):\n",
    "    s += sgl.user(\n",
    "        \"\"\"Please generate a high-level plan for solving the following question. As the first step, just say what method and idea you will use to solve the question. You can reorganize the information in the question. Do not do the actual calculation. Keep your response concise and within 80 words. Question: \"\"\"\n",
    "        + question\n",
    "    )\n",
    "    forks = s.fork(num_branches)\n",
    "    forks += sgl.assistant(sgl.gen(\"plan\", max_tokens=256, temperature=temp))\n",
    "    return forks\n",
    "\n",
    "\n",
    "def execute_plan(s, num_branches):\n",
    "    s += sgl.user(\n",
    "        \"\"\"The plan looks good! Now, use real numbers and do the calculation. Please solve the question step-by-step according to the high-level plan. Give me the final answer. Make your response short.\"\"\"\n",
    "    )\n",
    "    forks = s.fork(num_branches)\n",
    "    forks += sgl.assistant(sgl.gen(\"answer\", max_tokens=256, temperature=temp))\n",
    "    return forks\n",
    "\n",
    "\n",
    "def reflect_solution(s, num_branches):\n",
    "    s += sgl.user(\n",
    "        \"\"\"Okay. Now, evaluate your own solution and give it a score on a scale of 1 to 5. Please do rigorous check of the correctness.\"\"\"\n",
    "    )\n",
    "    forks = s.fork(num_branches)\n",
    "    forks += sgl.assistant(sgl.gen(\"score\", max_tokens=256, temperature=temp))\n",
    "    return forks\n",
    "\n",
    "\n",
    "def get_final_answer(s, num_branches):\n",
    "    s += sgl.user(\n",
    "        \"\"\"Based on your reflection, do you change your mind? Now, give me the final answer after careful consideration.\"\"\"\n",
    "    )\n",
    "    forks = s.fork(num_branches)\n",
    "    forks += sgl.assistant(sgl.gen(\"final_answer\", max_tokens=256, temperature=temp))\n",
    "    return forks\n",
    "\n",
    "\n",
    "@sgl.function\n",
    "def tree_search(s, question, num_branches):\n",
    "    \n",
    "    tree_log = []\n",
    "    parent = []\n",
    "    \n",
    "    plan_forks = propose_plan(s, question, num_branches)\n",
    "\n",
    "    sol_states = []\n",
    "    for plan in plan_forks:\n",
    "        forks = execute_plan(plan, num_branches)\n",
    "        sol_states.extend(forks)\n",
    "    \n",
    "    tree_log.append(sol_states)\n",
    "\n",
    "    ref_states = []\n",
    "    for sol in sol_states:\n",
    "        forks = reflect_solution(sol, num_branches)\n",
    "        ref_states.extend(forks)\n",
    "\n",
    "    ref_states = [k for k in ref_states if random.random() > 0.2]\n",
    "\n",
    "    tree_log.append(ref_states)\n",
    "\n",
    "    solutions = []\n",
    "    for sol in ref_states:\n",
    "        forks = get_final_answer(sol, num_branches)\n",
    "        solutions.append(forks)\n",
    "        \n",
    "    tree_log.append(solutions)\n",
    "    \n",
    "    solutions = [[s.text() for s in forks] for forks in solutions]\n",
    "\n",
    "    return tree_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:08<00:00,  4.35s/it]\n"
     ]
    }
   ],
   "source": [
    "ret_values = tree_search.run_batch(\n",
    "    arguments,\n",
    "    temperature=0,\n",
    "    backend=backend,\n",
    "    num_threads=args.parallel,\n",
    "    progress_bar=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 7 7\n"
     ]
    }
   ],
   "source": [
    "ret_value = ret_values[1]\n",
    "\n",
    "print(len(ret_value.ret_value[0]),\n",
    "        len(ret_value.ret_value[1]),\n",
    "        len(ret_value.ret_value[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Please generate a high-level plan for solving the following question. As the first step, just say what method and idea you will use to solve the question. You can reorganize the information in the question. Do not do the actual calculation. Keep your response concise and within 80 words. Question: A robe takes 2 bolts of blue fiber and half that much white fiber.  How many bolts in total does it take?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "To solve this problem, I will use the concept of ratios and proportions. I will first identify the ratio of blue fiber to white fiber, which is 2:1. Then, I will calculate the total number of bolts by adding the number of bolts of blue fiber to the number of bolts of white fiber.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "The plan looks good! Now, use real numbers and do the calculation. Please solve the question step-by-step according to the high-level plan. Give me the final answer. Make your response short.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Here's the step-by-step calculation:\n",
      "\n",
      "1. The ratio of blue fiber to white fiber is 2:1.\n",
      "2. Let's say the number of bolts of blue fiber is 2x. Then, the number of bolts of white fiber is x.\n",
      "3. Since the robe takes half as much white fiber as blue fiber, x = 2/2 = 1.\n",
      "4. Number of bolts of blue fiber = 2x = 2(1) = 2.\n",
      "5. Number of bolts of white fiber = x = 1.\n",
      "6. Total number of bolts = 2 + 1 = 3.\n",
      "\n",
      "The final answer is 3.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Okay. Now, evaluate your own solution and give it a score on a scale of 1 to 5. Please do rigorous check of the correctness.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "print(ret_value.ret_value[0][0].text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ret_values[0].ret_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:07<00:00,  3.71s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lines = [l for l in read_jsonl(args.data_path)]\n",
    "\n",
    "# Construct prompts\n",
    "num_branches = 2\n",
    "questions = []\n",
    "labels = []\n",
    "for i in range(len(lines[: args.num_questions])):\n",
    "    questions.append(lines[i][\"question\"])\n",
    "    labels.append(get_answer_value(lines[i][\"answer\"]))\n",
    "assert all(l != INVALID for l in labels)\n",
    "arguments = [{\"question\": q, \"num_branches\": num_branches} for q in questions]\n",
    "\n",
    "# Select backend\n",
    "backend = select_sglang_backend(args)\n",
    "\n",
    "# Run requests\n",
    "tic = time.time()\n",
    "states = tree_search.run_batch(\n",
    "    arguments,\n",
    "    temperature=0,\n",
    "    backend=backend,\n",
    "    num_threads=args.parallel,\n",
    "    progress_bar=True,\n",
    ")\n",
    "latency = time.time() - tic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_text = []\n",
    "for s in states:\n",
    "    answers_text.append([x for xs in s.ret_value for x in xs])\n",
    "\n",
    "preds = []\n",
    "for i in range(len(states)):\n",
    "    answers = [get_answer_value(v) for v in answers_text[i]]\n",
    "    preds.append(most_frequent_number(answers))\n",
    "\n",
    "# Compute accuracy\n",
    "acc = np.mean(np.array(preds) == np.array(labels))\n",
    "invalid = np.mean(np.array(preds) == INVALID)\n",
    "print(f\"Latency: {latency:.3f}\")\n",
    "print(f\"Invalid: {invalid:.3f}\")\n",
    "print(f\"Accuracy: {acc:.3f}\")\n",
    "\n",
    "# Write results\n",
    "dump_state_text(f\"tmp_output_{args.backend}.txt\", answers_text)\n",
    "\n",
    "with open(args.result_file, \"a\") as fout:\n",
    "    value = {\n",
    "        \"task\": \"tree_of_thought_gsm8k\",\n",
    "        \"backend\": args.backend,\n",
    "        \"num_gpus\": 1,\n",
    "        \"latency\": round(latency, 3),\n",
    "        \"accuracy\": round(acc, 3),\n",
    "        \"num_requests\": args.num_questions,\n",
    "        \"other\": {\n",
    "            \"num_questions\": args.num_questions,\n",
    "            \"parallel\": args.parallel,\n",
    "        },\n",
    "    }\n",
    "    fout.write(json.dumps(value) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sglang.lang.interpreter.ProgramState"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(states[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user : Please generate a high-level plan for solving the following question. As the first step, just say what method and idea you will use to solve the question. You can reorganize the information in the question. Do not do the actual calculation. Keep your response concise and within 80 words. Question: Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?\n"
     ]
    }
   ],
   "source": [
    "for m in states[0].messages():\n",
    "    print(m[\"role\"], \":\", m[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sglang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:06<00:00,  1.71s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "good_token = ' +'\n",
    "bad_token = ' -'\n",
    "step_tag = '   ки'\n",
    "\n",
    "path = \"HanningZhang/Llama3.1-Math-PRM\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(path)\n",
    "plus_tag_id = tokenizer.encode(' +')[-1]\n",
    "minus_tag_id = tokenizer.encode(' -')[-1]\n",
    "\n",
    "candidate_tokens = [plus_tag_id,minus_tag_id]\n",
    "step_tag_id = tokenizer.encode(f\" {step_tag}\")[-1] # 12902\n",
    "model = AutoModelForCausalLM.from_pretrained(path).eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116624"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_tag_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_for_prm = f\"{question} {output1}\"\n",
    "input_id = torch.tensor([tokenizer.encode(input_for_prm)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128000 <|begin_of_text|>\n",
      "18820 Jan\n",
      "295 et\n",
      "753 ’s\n",
      "78878  ducks\n",
      "11203  lay\n",
      "220  \n",
      "845 16\n",
      "19335  eggs\n",
      "824  per\n",
      "1938  day\n",
      "13 .\n",
      "3005  She\n",
      "50777  eats\n",
      "2380  three\n",
      "369  for\n",
      "17954  breakfast\n",
      "1475  every\n",
      "6693  morning\n",
      "323  and\n",
      "293  b\n",
      "2094 akes\n",
      "55404  muff\n",
      "1354 ins\n",
      "369  for\n",
      "1077  her\n",
      "4885  friends\n",
      "1475  every\n",
      "1938  day\n",
      "449  with\n",
      "3116  four\n",
      "13 .\n",
      "3005  She\n",
      "31878  sells\n",
      "279  the\n",
      "27410  remainder\n",
      "520  at\n",
      "279  the\n",
      "20957  farmers\n",
      "6 '\n",
      "3157  market\n",
      "7446  daily\n",
      "369  for\n",
      "400  $\n",
      "17 2\n",
      "824  per\n",
      "7878  fresh\n",
      "37085  duck\n",
      "19151  egg\n",
      "13 .\n",
      "2650  How\n",
      "1790  much\n",
      "304  in\n",
      "11441  dollars\n",
      "1587  does\n",
      "1364  she\n",
      "1304  make\n",
      "1475  every\n",
      "1938  day\n",
      "520  at\n",
      "279  the\n",
      "20957  farmers\n",
      "6 '\n",
      "3157  market\n",
      "30 ?\n",
      "15166  Step\n",
      "220  \n",
      "16 1\n",
      "25 :\n",
      "54765  Janet\n",
      "596 's\n",
      "78878  ducks\n",
      "11203  lay\n",
      "220  \n",
      "845 16\n",
      "19335  eggs\n",
      "824  per\n",
      "1938  day\n",
      "13 .\n",
      "116624  ки\n",
      "8468 Step\n",
      "220  \n",
      "17 2\n",
      "25 :\n",
      "3005  She\n",
      "50777  eats\n",
      "2380  three\n",
      "369  for\n",
      "17954  breakfast\n",
      "1475  every\n",
      "6693  morning\n",
      "11 ,\n",
      "779  so\n",
      "1364  she\n",
      "706  has\n",
      "220  \n",
      "845 16\n",
      "482  -\n",
      "220  \n",
      "18 3\n",
      "284  =\n",
      "220  \n",
      "1032 13\n",
      "19335  eggs\n",
      "2163  left\n",
      "13 .\n",
      "116624  ки\n",
      "8468 Step\n",
      "220  \n",
      "18 3\n",
      "25 :\n",
      "3005  She\n",
      "293  b\n",
      "2094 akes\n",
      "55404  muff\n",
      "1354 ins\n",
      "369  for\n",
      "1077  her\n",
      "4885  friends\n",
      "1475  every\n",
      "1938  day\n",
      "449  with\n",
      "3116  four\n",
      "19335  eggs\n",
      "11 ,\n",
      "779  so\n",
      "1364  she\n",
      "706  has\n",
      "220  \n",
      "1032 13\n",
      "482  -\n",
      "220  \n",
      "19 4\n",
      "284  =\n",
      "220  \n",
      "24 9\n",
      "19335  eggs\n",
      "2163  left\n",
      "13 .\n",
      "116624  ки\n",
      "8468 Step\n",
      "220  \n",
      "19 4\n",
      "25 :\n",
      "3005  She\n",
      "31878  sells\n",
      "279  the\n",
      "27410  remainder\n",
      "520  at\n",
      "279  the\n",
      "20957  farmers\n",
      "6 '\n",
      "3157  market\n",
      "7446  daily\n",
      "369  for\n",
      "400  $\n",
      "17 2\n",
      "824  per\n",
      "7878  fresh\n",
      "37085  duck\n",
      "19151  egg\n",
      "11 ,\n",
      "779  so\n",
      "1364  she\n",
      "3727  makes\n",
      "220  \n",
      "24 9\n",
      "353  *\n",
      "400  $\n",
      "17 2\n",
      "284  =\n",
      "400  $\n",
      "972 18\n",
      "1475  every\n",
      "1938  day\n",
      "520  at\n",
      "279  the\n",
      "20957  farmers\n",
      "6 '\n",
      "3157  market\n",
      "13 .\n",
      "578  The\n",
      "4320  answer\n",
      "374  is\n",
      "25 :\n",
      "220  \n",
      "972 18\n",
      "116624  ки\n"
     ]
    }
   ],
   "source": [
    "for i in input_id[0]:\n",
    "    print(i.item(), tokenizer.decode(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9182])\n"
     ]
    }
   ],
   "source": [
    "question = \"\"\"Janet\\u2019s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?\"\"\"\n",
    "output1 = \"\"\"Step 1: Janet's ducks lay 16 eggs per day. киStep 2: She eats three for breakfast every morning, so she has 16 - 3 = 13 eggs left. киStep 3: She bakes muffins for her friends every day with four eggs, so she has 13 - 4 = 9 eggs left. киStep 4: She sells the remainder at the farmers' market daily for $2 per fresh duck egg, so she makes 9 * $2 = $18 every day at the farmers' market. The answer is: 18 ки\"\"\" # 18 is right\n",
    "output2 = \"\"\"Step 1: Janet's ducks lay 16 eggs per day. киStep 2: She eats three for breakfast every morning, so she has 16 - 3 = 13 eggs left. киStep 3: She bakes muffins for her friends every day with four eggs, so she has 13 - 4 = 9 eggs left. киStep 4: She sells the remainder at the farmers' market daily for $2 per fresh duck egg, so she makes 9 * $2 = $17 every day at the farmers' market. The answer is: 17 ки\"\"\" # 17 is wrong\n",
    "\n",
    "output3 = \"\"\"Step 1: Janet's ducks lay 16 eggs per day. Step 2: She eats three for breakfast every morning, so she has 16 - 3 = 13 eggs left. Step 3: She bakes muffins for her friends every day with four eggs, so she has 13 - 4 = 9 eggs left. Step 4: She sells the remainder at the farmers' market daily for $2 per fresh duck egg, so she makes 9 * $2 = $18 every day at the farmers' market. The answer is: 18 ки\"\"\" # 17 is wrong\n",
    "\n",
    "for output in [output3]:\n",
    "    input_for_prm = f\"{question} {output}\"\n",
    "    input_id = torch.tensor([tokenizer.encode(input_for_prm)])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_id).logits[:,:,candidate_tokens]\n",
    "        scores = logits.softmax(dim=-1)[:,:,0] \n",
    "        step_scores = scores[input_id == step_tag_id]\n",
    "        print(step_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''If $x^3$ is a positive factor of $10!,$ how many possible integer values of $x$ are there?  (Reminder: For a positive integer $n$, the expression $n!$ stands for the product of the integers from 1 up to (and including) $n$.) \n",
    "\n",
    "To find the possible values of $x$, we need to find the prime factorization of $10!$. ки\n",
    "\n",
    "The prime factorization of $10!$ is $2^8 \\cdot 3^4 \\cdot 5^2 \\cdot 7$. ки\n",
    "\n",
    "Since $x^3$ is a positive factor of $10!$, we need to find the possible values of $x$ such that $x^3$ divides $10!$. ки\n",
    "\n",
    "We can start by finding the possible values of $x$ such that $x^3$ divides $2^8$. ки\n",
    "\n",
    "The possible values of $x$ such that $x^3$ divides $2^8$ are $1, 2, 4, 8$. ки\n",
    "\n",
    "We can then find the possible values of $x$ such that $x^3$ divides $3^4$. ки\n",
    "\n",
    "The possible values of $x$ such that $x^3$ divides $3^4$ are $1, 3$. ки\n",
    "\n",
    "We can then find the possible values of $x$ such that $x^3$ divides $5^2$. ки\n",
    "\n",
    "The possible values of $x$ such that $x^3$ divides $5^2$ are $1, 5$. ки\n",
    "\n",
    "We can then find the possible values of $x$ such that $x^3$ divides $7$. ки\n",
    "\n",
    "The possible values of $x$ such that $x^3$ divides $7$ are $1$. ки\n",
    "\n",
    "Now, we need to find the intersection of the possible values of $x$ for each prime factor. ки\n",
    "\n",
    "The intersection of the possible values of $x$ for each prime factor is $1$. ки\n",
    "\n",
    "Therefore, the possible values of $x$ are $1, 2, 4, 8, 3, 5$. ки\n",
    "\n",
    "There are 6 possible values of $x$. ки\n",
    "\n",
    "Answer: 6 ки'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 4096, padding_idx=128001)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cuda:7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5330, 0.6286, 0.4628, 0.3091, 0.1489, 0.1437, 0.2133, 0.2332, 0.2703,\n",
      "        0.2927, 0.3424, 0.2407, 0.2194, 0.1127, 0.2649, 0.3387],\n",
      "       device='cuda:7')\n"
     ]
    }
   ],
   "source": [
    "input_for_prm = f\"{text}\"\n",
    "input_id = torch.tensor([tokenizer.encode(input_for_prm)]).cuda(7)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(input_id).logits[:,:,candidate_tokens]\n",
    "    scores = logits.softmax(dim=-1)[:,:,0] \n",
    "    step_scores = scores[input_id == step_tag_id]\n",
    "    print(step_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5460, 0.7227, 0.7268, 0.6077, 0.4547, 0.4675, 0.5724, 0.5505, 0.5266,\n",
      "        0.5241, 0.5907, 0.5705, 0.6346, 0.3756, 0.3568], device='cuda:7')\n"
     ]
    }
   ],
   "source": [
    "text = '''If $x^3$ is a positive factor of $10!,$ how many possible integer values of $x$ are there?  (Reminder: For a positive integer $n$, the expression $n!$ stands for the product of the integers from 1 up to (and including) $n$.) Step 1: To find the possible values of $x$, we need to find the prime factorization of $10!$. киStep 2: The prime factorization of $10!$ is $2^8 \\cdot 3^4 \\cdot 5^2 \\cdot 7$. киStep 3: Since $x^3$ is a positive factor of $10!$, we need to find the possible values of $x$ such that $x^3$ divides $10!$. киStep 4: We can start by finding the possible values of $x$ such that $x^3$ divides $2^8$. киStep 5: The possible values of $x$ such that $x^3$ divides $2^8$ are $1, 2, 4, 8$. киStep 6: We can then find the possible values of $x$ such that $x^3$ divides $3^4$. киStep 7: The possible values of $x$ such that $x^3$ divides $3^4$ are $1, 3$. киStep 8: We can then find the possible values of $x$ such that $x^3$ divides $5^2$. киStep 9: The possible values of $x$ such that $x^3$ divides $5^2$ are $1, 5$. киStep 10: We can then find the possible values of $x$ such that $x^3$ divides $7$. киStep 11: The possible values of $x$ such that $x^3$ divides $7$ are $1$. киStep 12: Now, we need to find the intersection of the possible values of $x$ for each prime factor. киStep 13: The intersection of the possible values of $x$ for each prime factor is $1$. киStep 14: Therefore, the possible values of $x$ are $1, 2, 4, 8, 3, 5$. киStep 15: There are 6 possible values of $x$. The answer is: 6 ки'''\n",
    "\n",
    "input_for_prm = text\n",
    "input_id = torch.tensor([tokenizer.encode(input_for_prm)]).cuda(7)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(input_id).logits[:,:,candidate_tokens]\n",
    "    scores = logits.softmax(dim=-1)[:,:,0] \n",
    "    step_scores = scores[input_id == step_tag_id]\n",
    "    print(step_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "PROMPT = (\n",
    "    \"What is the range of the numeric output of a sigmoid node in a neural network?\"\n",
    ")\n",
    "\n",
    "RESPONSE1 = \"The output of a sigmoid node is bounded between -1 and 1.\"\n",
    "RESPONSE2 = \"The output of a sigmoid node is bounded between 0 and 1.\"\n",
    "\n",
    "CONVS = [\n",
    "    [{\"role\": \"user\", \"content\": PROMPT}, {\"role\": \"assistant\", \"content\": RESPONSE1}],\n",
    "    [{\"role\": \"user\", \"content\": PROMPT}, {\"role\": \"assistant\", \"content\": RESPONSE2}],\n",
    "]\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Skywork/Skywork-Reward-Llama-3.1-8B-v0.2\")\n",
    "prompts = tokenizer.apply_chat_template(CONVS, tokenize=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 Jul 2024\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nWhat is the range of the numeric output of a sigmoid node in a neural network?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe output of a sigmoid node is bounded between -1 and 1.<|eot_id|>',\n",
       " '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 Jul 2024\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nWhat is the range of the numeric output of a sigmoid node in a neural network?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe output of a sigmoid node is bounded between 0 and 1.<|eot_id|>']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward: -24.25\n",
      "reward: 1.0703125\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"http://localhost:10087/judge\"\n",
    "data = {\"model\": \"Skywork/Skywork-Reward-Llama-3.1-8B-v0.2\", \"text\": prompts}\n",
    "\n",
    "responses = requests.post(url, json=data).json()\n",
    "for response in responses:\n",
    "    # print(type(response))\n",
    "    print(f\"reward: {response['embedding'][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'embedding': [-24.25],\n",
       "  'meta_info': {'prompt_tokens': 69,\n",
       "   'id': 'b40f91f07d0d41d2ab8a04fd5b2079a5'}},\n",
       " {'embedding': [1.109375],\n",
       "  'meta_info': {'prompt_tokens': 69,\n",
       "   'id': '57386a90ab164526b31fa958e9821de6'}}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/shibo/anaconda3/envs/sgl-py310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/data/shibo/anaconda3/envs/sgl-py310/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 179, 4096])\n",
      "torch.Size([1, 179, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 179, 4096])\n",
      "torch.Size([1, 179, 1])\n",
      "torch.Size([1, 1])\n",
      "Score for response 1: 13.8125\n",
      "Score for response 2: -9.25\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "\n",
    "# Load model and tokenizer\n",
    "device = \"cuda:1\"\n",
    "model_name = \"Skywork/Skywork-Reward-Llama-3.1-8B-v0.2\"\n",
    "rm = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=device,\n",
    "    # attn_implementation=\"flash_attention_2\",\n",
    "    num_labels=1,\n",
    ")\n",
    "rm_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "prompt = \"Jane has 12 apples. She gives 4 apples to her friend Mark, then buys 1 more apple, and finally splits all her apples equally among herself and her 2 siblings. How many apples does each person get?\"\n",
    "response1 = \"1. Jane starts with 12 apples and gives 4 to Mark. 12 - 4 = 8. Jane now has 8 apples.\\n2. Jane buys 1 more apple. 8 + 1 = 9. Jane now has 9 apples.\\n3. Jane splits the 9 apples equally among herself and her 2 siblings (3 people in total). 9 ÷ 3 = 3 apples each. Each person gets 3 apples.\"\n",
    "response2 = \"1. Jane starts with 12 apples and gives 4 to Mark. 12 - 4 = 8. Jane now has 8 apples.\\n2. Jane buys 1 more apple. 8 + 1 = 9. Jane now has 9 apples.\\n3. Jane splits the 9 apples equally among her 2 siblings (2 people in total). 9 ÷ 2 = 4.5 apples each. Each person gets 4 apples.\"\n",
    "\n",
    "conv1 = [{\"role\": \"user\", \"content\": prompt}, {\"role\": \"assistant\", \"content\": response1}]\n",
    "conv2 = [{\"role\": \"user\", \"content\": prompt}, {\"role\": \"assistant\", \"content\": response2}]\n",
    "\n",
    "# Format and tokenize the conversations\n",
    "# If you use `tokenize=False` with `apply_chat_template` and `tokenizer()` to tokenize the conversation,\n",
    "# remeber to remove the duplicated BOS token.\n",
    "conv1_tokenized = rm_tokenizer.apply_chat_template(conv1, tokenize=True, return_tensors=\"pt\").to(device)\n",
    "conv2_tokenized = rm_tokenizer.apply_chat_template(conv2, tokenize=True, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# Get the reward scores\n",
    "with torch.no_grad():\n",
    "    score1 = rm(conv1_tokenized).logits[0][0].item()\n",
    "    score2 = rm(conv2_tokenized).logits[0][0].item()\n",
    "print(f\"Score for response 1: {score1}\")\n",
    "print(f\"Score for response 2: {score2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.Size([1, 179, 4096])\n",
    "# torch.Size([1, 179, 1])\n",
    "# torch.Size([1, 1])\n",
    "# torch.Size([1, 179, 4096])\n",
    "# torch.Size([1, 179, 1])\n",
    "# torch.Size([1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = rm(conv1_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LlamaForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sgl-py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
