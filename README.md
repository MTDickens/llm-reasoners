![logo](assets/reasoners_icon.png#pic_center)

<p align="center">
  <a href="https://www.llm-reasoners.net/">é¦–é¡µ</a>
  |
  <a href="https://arxiv.org/abs/2404.05221">è®ºæ–‡ (COLM2024)</a>
  |
  <a href="https://www.llm-reasoners.net/blog">åšå®¢</a>
  |
  <a href="https://discord.gg/PxDJby9W">Discord</a>
  |
  <a href="https://maitrix.org/">@Maitrix.org</a>
</p>

---

**LLM Reasoners** æ˜¯ä¸€ä¸ªæ—¨åœ¨åˆ©ç”¨å…ˆè¿›ç®—æ³•å¢å¼ºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ‰§è¡Œå¤æ‚æ¨ç†èƒ½åŠ›çš„åº“ã€‚å®ƒæä¾›ï¼š

-   **å‰æ²¿çš„æ¨ç†ç®—æ³•**

    è¯¥åº“æä¾›äº†ç”¨äº LLM æ¨ç†çš„æœ€æ–°æœç´¢ç®—æ³•ï¼Œä¾‹å¦‚ï¼š

    -   [Reasoner Agent](example/ReasonerAgent-Web) ([Deng et al., 2025](https://reasoner-agent.maitrix.org/))
    -   [ä½¿ç”¨ PRM è¿›è¡Œæ¨ç†æ—¶æ‰©å±•](examples/Inference-Scaling-SGL/math500) ([Snell et al., 2024](https://arxiv.org/abs/2408.03314))
    -   [é€šè¿‡è§„åˆ’è¿›è¡Œæ¨ç†ï¼ˆReasoning-via-Planningï¼‰ï¼ŒMCTS](examples/RAP) ([Hao et al., 2023](https://arxiv.org/abs/2305.14992))
    -   [æ€ç»´æ ‘ï¼ˆTree-of-Thoughtsï¼‰ï¼ŒBFS](examples/ToT) ([Yao et al., 2023](https://arxiv.org/abs/2305.10601))

    <details>
      <summary>(æ˜¾ç¤ºæ›´å¤šæ”¯æŒçš„ç®—æ³•)</summary>

    -   [StructChem](examples/StructChem) ([Ouyang et al., 2023](https://arxiv.org/abs/2311.09656))
    -   [æ€ç»´é“¾ï¼ˆChain-of-thoughtsï¼‰](examples/CoT) ([Wei et al., 2022](https://arxiv.org/abs/2201.11903))
    -   [ä»å°‘åˆ°å¤šæç¤ºï¼ˆLeast-to-most promptingï¼‰](examples/Least-to-most) ([Zhou et al., 2022](https://arxiv.org/abs/2205.10625))
    -   [æ€ç»´æ ‘ï¼ˆTree-of-Thoughtsï¼‰ï¼ŒDFS](examples/ToT) ([Yao et al., 2023](https://arxiv.org/abs/2305.10601))
    -   [è‡ªè¯„ä¼°å¼•å¯¼è§£ç ï¼ˆSelf-Eval Guided Decodingï¼‰ï¼ŒBeam Search](examples/Self-Eval) ([Xie et al., 2023](https://arxiv.org/abs/2305.00633))
    -   [Grace è§£ç ](examples/Grace) ([Khalifa et al., 2023](https://arxiv.org/abs/2305.14934))
    -   [Eurus](examples/Eurus) ([Yuan et al., 2024](https://arxiv.org/abs/2404.02078))
    -   [PromptAgent](examples/PromptAgent) ([Wang et al., 2023](https://arxiv.org/abs/2310.16427))
    -   [DRPO](examples/DRPO) ([Singla et al., 2024](https://aclanthology.org/2024.emnlp-main.1220/))

    </details>

-   **ç›´è§‚çš„å¯è§†åŒ–ä¸è§£é‡Š**ï¼šæˆ‘ä»¬çš„åº“æä¾›äº†ä¸€ä¸ª[å¯è§†åŒ–å·¥å…·](https://www.llm-reasoners.net/)ï¼Œå¸®åŠ©ç”¨æˆ·ç†è§£æ¨ç†è¿‡ç¨‹ã€‚å³ä½¿å¯¹äºåƒè’™ç‰¹å¡æ´›æ ‘æœç´¢ï¼ˆMonte-Carlo Tree Searchï¼‰è¿™æ ·çš„å¤æ‚æ¨ç†ç®—æ³•ï¼Œç”¨æˆ·ä¹Ÿåªéœ€**ä¸€è¡Œ Python ä»£ç **å³å¯è½»æ¾è¯Šæ–­å’Œç†è§£å…¶è¿‡ç¨‹ã€‚è¯·å‚é˜…æ•™ç¨‹ [notebook](demo.ipynb) ä¸­çš„ç¤ºä¾‹ã€‚

-   **é«˜æ•ˆçš„ LLM æ¨ç†**ï¼šæˆ‘ä»¬çš„åº“é€šè¿‡é›†æˆé«˜æ€§èƒ½ LLM æ¨ç†æ¡†æ¶ [SGLang](https://github.com/sgl-project/sglang) æ¥ä¼˜åŒ–é«˜çº§æ¨ç†æŠ€æœ¯çš„æ€§èƒ½ï¼Œè¯¥æ¡†æ¶æ”¯æŒç»“æ„åŒ–ç”Ÿæˆï¼ˆè¯·æŸ¥çœ‹æ­¤ [å¸–å­](https://x.com/MaitrixOrg/status/1885387184557199857) å’Œ [ç¤ºä¾‹](https://github.com/maitrix-org/llm-reasoners/tree/main/examples/Inference-Scaling-SGL/math500)ï¼‰ã€‚æˆ‘ä»¬è¿˜æ”¯æŒå…¶ä»– LLM åç«¯ï¼Œå¦‚ `huggingface transformers`ã€`OpenAI API`ã€`Exllama`ã€`fairscale`ã€`llama.cpp` ç­‰ã€‚

-   **ä¸¥è°¨çš„å®ç°ä¸å¯å¤ç°æ€§**ï¼šæˆ‘ä»¬åœ¨å®ç°ä¸­ä¼˜å…ˆè€ƒè™‘ç²¾ç¡®æ€§å’Œå¯é æ€§ï¼Œç¡®ä¿æˆ‘ä»¬çš„ç®—æ³•ä¸ä»…æ˜¯ç†è®ºæ¦‚å¿µï¼Œè€Œä¸”æ˜¯å®ç”¨çš„å·¥å…·ã€‚LLM Reasoners ä¸­å®ç°çš„æ‰€æœ‰æ–¹æ³•éƒ½ç»è¿‡ç²¾å¿ƒè®¾è®¡ï¼Œä»¥å¿ å®äºå…¶åŸå§‹è¡¨è¿°å’Œæ€§èƒ½ã€‚å®ƒä¸ºæˆ‘ä»¬åœ¨ COLM2024 ä¸Šå‘è¡¨çš„æ¨ç†ç®—æ³•[åˆ†æ](https://arxiv.org/abs/2404.05221)æä¾›äº†æ”¯æŒã€‚

    <details>

    <summary> (å¯å¤ç°æ€§ç¤ºä¾‹) </summary>

    -   LLM Reasoners å·²ç»è¿‡æµ‹è¯•ï¼Œå¯æˆåŠŸå¤ç° [æ€ç»´æ ‘ï¼ˆTree-of-Thoughtsï¼‰](https://arxiv.org/abs/2305.10601)ã€[å¼•å¯¼è§£ç ï¼ˆGuided Decodingï¼‰](https://arxiv.org/abs/2305.00633) å’Œ [GRACE è§£ç ](https://arxiv.org/abs/2305.14934) çš„å®˜æ–¹å®ç°æ€§èƒ½ã€‚æˆ‘ä»¬åˆ—å‡ºäº†å…¶è®ºæ–‡ä¸­æŠ¥å‘Šçš„ç»“æœ / ä»å…¶å®˜æ–¹ä»“åº“å¤ç°çš„ç»“æœä»¥ä¾›å‚è€ƒ (â€ )ã€‚éƒ¨åˆ†ç»“æœåŸºäºå‰ 100 ä¸ªæ ·æœ¬çš„å­é›† (*)ã€‚

    <div align="center">

    |æ–¹æ³•|åŸºç¡€ LLM|GSM8k|
    |--|--|--|
    |[å¼•å¯¼è§£ç ](https://arxiv.org/abs/2305.00633)<sup>â€ </sup>|CodeX (PAL)|0.80|-|-|-|-|-|
    |å¼•å¯¼è§£ç |CodeX (PAL)|[0.83\*](examples/guided_gsm8k)|-|-|-|-|-|

    |æ–¹æ³•|åŸºç¡€ LLM|Game of 24|
    |--|--|--|
    |[æ€ç»´æ ‘](https://arxiv.org/abs/2305.10601)<sup>â€ </sup>|GPT-3.5-turbo|0.22|
    |æ€ç»´æ ‘|GPT-3.5-turbo|[0.22](examples/tot_game24)|

    |æ–¹æ³•|åŸºç¡€ LLM|GSM8k|
    |--|--|--|
    |[GRACE è§£ç ](https://arxiv.org/abs/2305.14934)<sup>â€ </sup>|Flan-T5-Large (Fine-tuned)|0.34|-|-|-|-|-|
    |GRACE è§£ç | Flan-T5-Large (Fine-tuned)|[0.33\*](examples/grace_gsm8k)|-|-|-|-|-|
    </div>

    </details>

## æœ€æ–°æ¶ˆæ¯
-   2025å¹´2æœˆ21æ—¥ï¼šæˆ‘ä»¬é›†æˆäº† Deepseek R1 ([ç¤ºä¾‹](https://github.com/maitrix-org/llm-reasoners/tree/main/examples/LongCoT_Search/ProsQA))ã€‚å¦è¯·æŸ¥çœ‹æˆ‘ä»¬å¯¹ R1 æœç´¢æ¨¡å¼çš„åˆ†æ ([å¸–å­](https://x.com/MaitrixOrg/status/1893017035753574799))ã€‚

-   2025å¹´2æœˆ6æ—¥ï¼šå¾ˆé«˜å…´æ¨å‡º **ReasonerAgent** - ä¸€ä¸ªå®Œå…¨å¼€æºã€å¼€ç®±å³ç”¨çš„æ™ºèƒ½ä½“ï¼Œå¯ä»¥åœ¨ Web æµè§ˆå™¨ä¸­è¿›è¡Œç ”ç©¶ ğŸ§ å¹¶å›ç­”æ‚¨çš„æŸ¥è¯¢ã€‚è¯·æŸ¥çœ‹æ­¤ [å¸–å­](https://x.com/MaitrixOrg/status/1887584291087098063)ï¼Œå¹¶åœ¨æ­¤å¤„æ¢ç´¢[ä»£ç ](https://github.com/maitrix-org/llm-reasoners/tree/main/examples/ReasonerAgent-Web)ï¼
-   2025å¹´1æœˆ31æ—¥ï¼šLLM Reasoners å·²é›†æˆ [SGLang](https://github.com/sgl-project/sglang)ã€‚åªéœ€ä¸€è¡Œä»£ç æ›´æ”¹ï¼Œå³å¯äº«å— 100 å€åŠ é€Ÿï¼åƒç”¨äºæ¨ç†æ—¶æ‰©å±•ï¼ˆinference-time scalingï¼‰çš„ PRM å¼•å¯¼æœç´¢ç­‰æ–°åº”ç”¨ä¹Ÿå·²å¯ç”¨ã€‚åœ¨æ­¤ [å¸–å­](https://x.com/MaitrixOrg/status/1885387184557199857) ä¸­æŸ¥çœ‹æ›´å¤šè¯¦æƒ…ã€‚
-   2024å¹´12æœˆ20æ—¥ï¼šæˆ‘ä»¬ç°åœ¨æ”¯æŒåœ¨ [BrowserGym](https://github.com/ServiceNow/BrowserGym) çš„ Web ç¯å¢ƒä¸­ä½¿ç”¨è§„åˆ’ç®—æ³•ï¼ˆMCTSã€DFS/BFSã€Beam Searchï¼‰ï¼ŒæŸ¥çœ‹ [README](https://github.com/maitrix-org/llm-reasoners/tree/main/examples/browsergym) å°è¯•ä¸€ä¸‹ï¼

<details>

<summary>(æ˜¾ç¤ºæ›´å¤šæ–°é—»)</summary>

-   2024å¹´11æœˆ13æ—¥ï¼šæˆ‘ä»¬é›†æˆäº† [DRPO](https://aclanthology.org/2024.emnlp-main.1220/)ï¼Œä¸€ç§åœ¨ EMNLP 2024 å‘è¡¨çš„å…è°ƒä¼˜å¯¹é½æ–¹æ³• ([é“¾æ¥](https://github.com/maitrix-org/llm-reasoners/tree/main/examples/DRPO))ã€‚

-   2024å¹´7æœˆ10æ—¥ï¼šæˆ‘ä»¬å…³äº [LLM Reasoners](https://arxiv.org/abs/2404.05221) çš„è®ºæ–‡å·²è¢« [COLM 2024](https://colmweb.org/index.html) æ¥æ”¶ï¼
-   2024å¹´6æœˆ24æ—¥ï¼š[PromptAgent](https://arxiv.org/abs/2310.16427) å·²åŠ å…¥ LLM Reasonersï¼è®©å®ƒå¸®åŠ©æ‚¨ä¸ºæ‚¨çš„ä»»åŠ¡å†™ä¸‹ä¸€ä¸ªè¶…è¯¦ç»†çš„æç¤º ([æ­¤å¤„](https://github.com/maitrix-org/llm-reasoners/tree/main/examples/PromptAgent))ã€‚
-   2024å¹´5æœˆ14æ—¥ï¼šæŸ¥çœ‹ [Eurus](https://arxiv.org/abs/2404.02078)ï¼Œä¸€å¥—ä¸ºæ¨ç†ä¼˜åŒ–çš„ LLMã€‚å€ŸåŠ© LLM Reasonersï¼ŒEurus-RM å¯ä»¥è½»æ¾å°† Llama-8B åœ¨ GSM8k ä¸Šçš„æ€§èƒ½ä» 0.49 æå‡åˆ° 0.73 ğŸ“ˆ ([ä»£ç ](examples/Eurus))ã€‚
-   2024å¹´5æœˆ2æ—¥ï¼šæˆ‘ä»¬é›†æˆäº†ç¬¬ä¸€ä¸ªç”¨äºç§‘å­¦æ¨ç†çš„æ–¹æ³• [StructChem](https://arxiv.org/abs/2311.09656)ï¼åœ¨æ­¤å¤„æŸ¥çœ‹ [ä»£ç ](https://github.com/maitrix-org/llm-reasoners/tree/main/examples/StructChem)ã€‚
-   2024å¹´4æœˆ22æ—¥ï¼šæˆ‘ä»¬é›†æˆäº† [Llama-3](https://github.com/meta-llama/llama3)ï¼Œå¹¶æä¾›äº†é¢å¤–çš„å®ç”¨ APIï¼ˆä¾‹å¦‚ï¼Œè‡ªå®šä¹‰ EOS æ ‡è®°ï¼Œè®¡ç®—ä¼¼ç„¶ï¼‰
-   **2024å¹´4æœˆ8æ—¥ï¼šæˆ‘ä»¬ä»‹ç» LLM Reasoners çš„æ–°[è®ºæ–‡](assets/Reasoners.pdf)å·²å‘å¸ƒï¼**
-   2024å¹´3æœˆ29æ—¥ï¼š[Grace è§£ç ](https://arxiv.org/abs/2305.14934) å·²è¢«æ•´åˆï¼
-   2023å¹´10æœˆ25æ—¥ï¼šå…³äº LLM Reasoners å¯è§†åŒ–å·¥å…·çš„[è§†é¢‘æ•™ç¨‹](https://www.youtube.com/watch?v=5QfOxtiw_ZU)å·²ä¸Šçº¿ã€‚

-   2023å¹´10æœˆ23æ—¥ï¼šReasoning-via-Planningï¼ˆé€šè¿‡è§„åˆ’è¿›è¡Œæ¨ç†ï¼‰å·²è¢« EMNLP 2023 æ¥æ”¶ï¼æŸ¥çœ‹æˆ‘ä»¬æ›´æ–°äº†ç»“æœå’Œè®¨è®ºçš„[è®ºæ–‡](https://arxiv.org/abs/2305.14992)ï¼
</details>

## åº“ä»‹ç»

![åº“ç»“æ„](assets/figure2_reasoners_v5.png)

æˆ‘ä»¬å°† LLM æ¨ç†ç®—æ³•æŠ½è±¡ä¸ºä¸‰ä¸ªå…³é”®ç»„ä»¶ï¼š*å¥–åŠ±å‡½æ•° (reward function)*ã€*ä¸–ç•Œæ¨¡å‹ (world model)* å’Œ *æœç´¢ç®—æ³• (search algorithm)*ï¼ˆå‚è§æˆ‘ä»¬[è®ºæ–‡](https://arxiv.org/abs/2404.05221)ä¸­çš„è¡¨è¿°ï¼‰ï¼Œåˆ†åˆ«å¯¹åº”åº“ä¸­çš„ä¸‰ä¸ªç±»ï¼š<tt>SearchConfig</tt>ã€<tt>WorldModel</tt> å’Œ <tt>SearchAlgorithm</tt>ã€‚æ­¤å¤–ï¼Œè¿˜æœ‰ç”¨äºæ”¯æŒå…¶ä»–æ¨¡å—çš„ <tt>LLM API</tt>ã€ç”¨äºè¯„ä¼°æˆ–è°ƒè¯•æ¨ç†ç®—æ³•çš„ <tt>Benchmark</tt>ï¼ˆåŸºå‡†æµ‹è¯•ï¼‰å’Œ <tt>Visualization</tt>ï¼ˆå¯è§†åŒ–ï¼‰ï¼ˆå›¾ä¸­ä¸­éƒ¨ï¼‰ã€‚è¦ä¸ºç‰¹å®šé¢†åŸŸå®ç°ä¸€ä¸ªæ¨ç†ç®—æ³•ï¼ˆä¸€ä¸ª <tt>Reasoner</tt> å¯¹è±¡ï¼‰ï¼Œç”¨æˆ·å¯ä»¥ç»§æ‰¿ <tt>SearchConfig</tt> å’Œ <tt>WorldModel</tt> ç±»ï¼Œå¹¶å¯¼å…¥ä¸€ä¸ªé¢„å…ˆå®ç°çš„ <tt>SearchAlgorithm</tt>ã€‚æˆ‘ä»¬è¿˜å±•ç¤ºäº†ä¸€ä¸ªä½¿ç”¨ LLM Reasoners é€šè¿‡ RAP è§£å†³ Blocksworld é—®é¢˜çš„å…·ä½“ç¤ºä¾‹ï¼ˆå›¾åº•éƒ¨ï¼‰ã€‚

## å¿«é€Ÿå¯¼è§ˆ
è®©æˆ‘ä»¬çœ‹ä¸€ä¸‹åœ¨ Blocksworld é—®é¢˜ä¸Šè¿›è¡Œæ¨ç†çš„ä»£ç ã€‚è¯·æ³¨æ„ï¼Œæ­¤ä»£ç ä¸ºæ¼”ç¤ºç›®çš„è¿›è¡Œäº†ç®€åŒ–ï¼ˆå¯è¿è¡Œçš„ notebook è¯·å‚è§[æ­¤å¤„](demo.ipynb)ï¼‰ã€‚

ç¬¬ä¸€æ­¥æ˜¯å®šä¹‰ä¸–ç•Œæ¨¡å‹ï¼šä½ éœ€è¦åœ¨ `init_state` ä¸­æ ¹æ®é—®é¢˜è®¾ç½®åˆå§‹çŠ¶æ€ï¼Œåœ¨ `is_terminal` ä¸­åˆ¤æ–­ä¸€ä¸ªçŠ¶æ€æ˜¯å¦ä¸ºç»ˆæ­¢çŠ¶æ€ï¼Œæœ€é‡è¦çš„æ˜¯ï¼Œç”¨ `step` å®šä¹‰ä¸–ç•ŒåŠ¨æ€ï¼š
```python
from typing import NamedTuple
import utils
from reasoners import WorldModel, LanguageModel
import copy

BWState = str
BWAction = str

class BlocksWorldModel(WorldModel[BWState, BWAction]):
    def __init__(self,
                 base_model: LanguageModel,
                 prompt: dict) -> None:
        super().__init__()
        self.base_model = base_model
        self.prompt = prompt

    def init_state(self) -> BWState:
        # ä»ç»™å®šé—®é¢˜ä¸­æå–åˆå§‹çŠ¶æ€
        # ä¾‹å¦‚ï¼š"the red block is clear, the blue block is clear..."
        return BWState(utils.extract_init_state(self.example))

    def step(self, state: BWState, action: BWAction) -> tuple[BWState, dict]:
        # è°ƒç”¨ LLM é¢„æµ‹çŠ¶æ€è½¬ç§»
        state = copy.deepcopy(state)
        # åŠ è½½æç¤ºè®© LLM é¢„æµ‹ä¸‹ä¸€ä¸ªçŠ¶æ€
        # ä¾‹å¦‚ï¼š"... I have that <state>, if I <action>, then ..."
        world_update_prompt = self.prompt["update"].replace("<state>", state).replace("<action>", action)
        world_output = self.base_model.generate([world_update_prompt],
                                    eos_token_id="\n", hide_input=True, temperature=0).text[0].strip()
        new_state = utils.process_new_state(world_output)
        # åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬å¾—åˆ°äº†æ‰§è¡ŒåŠ¨ä½œåçš„æ–°çŠ¶æ€
        # ä¸‹é¢çš„éƒ¨åˆ†æ˜¯ä¸ºäº†åŠ é€Ÿå¥–åŠ±è®¡ç®—

        # æˆ‘ä»¬æƒ³æ£€æŸ¥å·²æ»¡è¶³å­ç›®æ ‡çš„æ¯”ä¾‹ï¼Œå¹¶å°†å…¶ç”¨ä½œå¥–åŠ±çš„ä¸€éƒ¨åˆ†
        # å› ä¸ºæˆ‘ä»¬å·²ç»é¢„æµ‹äº†æ–°çŠ¶æ€ï¼Œæ‰€ä»¥å¯ä»¥åœ¨è¿™é‡Œæ–¹ä¾¿åœ°æ£€æŸ¥å®ƒ
        goal_reached = utils.goal_check(utils.extract_goals(self.example, new_state))
        # è¿”å›æ–°çŠ¶æ€å’Œé™„åŠ å­—å…¸ï¼ˆå°†ä¼ é€’ç»™å¥–åŠ±å‡½æ•°ï¼‰
        return new_state, {"goal_reached": goal_reached}

    def is_terminal(self, state: BWState) -> bool:
        # å®šä¹‰ç»ˆæ­¢çŠ¶æ€çš„æ¡ä»¶ä»¥åœæ­¢æœç´¢
        # ä¾‹å¦‚ï¼šæ‰€æœ‰å­ç›®æ ‡éƒ½å·²æ»¡è¶³
        if utils.goal_check(utils.extract_goals(self.example), state.blocks_state) == 1:
            return True
        return False
```
ç„¶åï¼Œéœ€è¦è€ƒè™‘å¦‚ä½•æœç´¢æœ€ä¼˜çš„æ¨ç†é“¾ã€‚è¿™æ¶‰åŠåˆ°ä½¿ç”¨ `get_actions` è·å–ç»™å®šçŠ¶æ€ä¸‹çš„åŠ¨ä½œç©ºé—´ï¼Œä»¥åŠæœ€é‡è¦çš„ã€ä½œä¸ºæ¨ç†æŒ‡å¯¼çš„ `reward`ï¼ˆå¥–åŠ±ï¼‰ã€‚å¯¹äºè’™ç‰¹å¡æ´›æ ‘æœç´¢ï¼ˆMonte-Carlo Tree Searchï¼‰ï¼Œæˆ‘ä»¬å¯ä»¥é¢å¤–å®šä¹‰ä¸€ä¸ª `fast_reward` æ¥åŠ é€Ÿæ¨æ¼”ï¼ˆroll-outï¼‰é˜¶æ®µã€‚
```python
import utils
from world_model import BWState, BWAction
from reasoners import SearchConfig, LanguageModel
class BWConfig(SearchConfig):
    def __init__(self,
                 base_model: LanguageModel,
                 prompt: dict,
                 reward_alpha=0.5,
                 goal_reward_default=0.,
                 goal_reached_reward=100) -> None:
        super().__init__()
        self.base_model = base_model
        self.example = None
        self.prompt = prompt
        # ä¸€äº›ç”¨äºè®¡ç®—å¿«é€Ÿå¥–åŠ±æˆ–å¥–åŠ±çš„å‚æ•°ï¼ˆä¸‹é¢è§£é‡Šï¼‰
        self.reward_alpha = reward_alpha
        self.goal_reward_default = goal_reward_default
        self.goal_reached_reward = goal_reached_reward

    def get_actions(self, state: BWState) -> list[BWAction]:
        # ä½¿ç”¨åŸºäºè§„åˆ™çš„å‡½æ•°æå–æ‰€æœ‰åˆæ³•åŠ¨ä½œ
        return utils.generate_all_actions(state)

    def fast_reward(self, state: BWState, action: BWAction) -> tuple[float, dict]:
        # æ„å»ºä¸€ä¸ªä¸Šä¸‹æ–‡å­¦ä¹ æç¤ºï¼ˆç±»ä¼¼äºæ€ç»´é“¾æ¨ç†ä¸­ä½¿ç”¨çš„æç¤ºï¼‰
        inputs = self.prompt["icl"].replace("<init_state>", state)\
            .replace("<goals>", utils.extract_goals(self.example))
        # åœ¨æç¤ºåè¿æ¥ä¸€ä¸ªå€™é€‰åŠ¨ä½œï¼Œå¹¶æµ‹è¯•å…¶å¯¹æ•°ä¼¼ç„¶
        intuition = self.base_model.get_loglikelihood(inputs, [inputs + action])[0]
        # å¥–åŠ±æ˜¯ç›´è§‰å’Œç›®æ ‡æ»¡è¶³åº¦çš„ç»„åˆ
        # åœ¨ fast_reward ä¸­ï¼Œæˆ‘ä»¬è·³è¿‡ç›®æ ‡æ»¡è¶³åº¦çš„è®¡ç®—ï¼Œä½¿ç”¨é»˜è®¤å€¼
        fast_reward = intuition * self.reward_alpha + self.goal_reward_default * (1 - self.reward_alpha)
        # ç¼“å­˜ä¸€äº›ä¿¡æ¯ä¾›ç¨åå¥–åŠ±è®¡ç®—ä½¿ç”¨ï¼ˆå°†ä¼ é€’ç»™ `reward` å‡½æ•°ï¼‰
        details = {'intuition': intuition}
        return fast_reward, details

    def reward(self, state: BWState, action: BWAction,
               intuition: float = None,
               goal_reached: tuple[bool, float] = None) -> float:
        # æ³¨æ„ `intuition`ï¼ˆåœ¨ `fast_reward` ä¸­ç¼“å­˜ï¼‰å’Œ `goal_reached`ï¼ˆåœ¨ `step` ä¸­ç¼“å­˜ï¼‰ä¼šè‡ªåŠ¨ä½œä¸ºå‚æ•°ä¼ é€’ç»™æ­¤å¥–åŠ±å‡½æ•°
        if goal_reached == 1:
            # å¦‚æœè¾¾åˆ°ç›®æ ‡çŠ¶æ€ï¼Œæˆ‘ä»¬å°†åˆ†é…ä¸€ä¸ªå¤§çš„å¥–åŠ±
            goal_reward = self.goal_reached_reward
        else:
            # å¦åˆ™æ ¹æ®å·²æ»¡è¶³å­ç›®æ ‡çš„æ¯”ä¾‹åˆ†é…å¥–åŠ±
            goal_reward = goal_reached
        # å¥–åŠ±æ˜¯ç›´è§‰å’Œç›®æ ‡æ»¡è¶³åº¦çš„ç»„åˆ
        reward = intuition * self.reward_alpha + goal_reward * (1 - self.reward_alpha)
        # è¿”å›å¥–åŠ±å’Œä¸€ä¸ªé™„åŠ å­—å…¸ï¼ˆå°†ä¿å­˜åœ¨æ—¥å¿—ä¸­ä¾›ä»¥åå¯è§†åŒ–ï¼‰
        return reward, {'intuition': intuition, 'goal_reached': goal_reached}
```
ç°åœ¨ï¼Œæˆ‘ä»¬å‡†å¤‡åº”ç”¨æ¨ç†ç®—æ³•æ¥è§£å†³é—®é¢˜ï¼š
```python
from reasoners.algorithm import MCTS
from reasoners.lm import LLaMAModel
from world_model import BlocksWorldModel
from search_config import BWConfig

llama_model = LLaMAModel(llama_ckpts, llama_size, max_batch_size=1)
with open(prompt_path) as f:
    prompt = json.load(f)
world_model = BlocksWorldModel(base_model=base_model, prompt=prompt)
config = BWConfig(base_model=llama_model, prompt=prompt)
# ä¿å­˜æ¯æ¬¡è¿­ä»£çš„å†å²è®°å½•ä»¥ä¾›å¯è§†åŒ–
search_algo = MCTS(output_trace_in_each_iter=True)
reasoner = Reasoner(world_model=world_model, search_config=config, search_algo=search_algo)
for i, example in enumerate(dataset):
    algo_output = reasoner(example)
    # å°† MCTS ç»“æœä¿å­˜ä¸º pickle æ–‡ä»¶
    with open(os.path.join(log_dir, 'algo_output', f'{resume + i + 1}.pkl'), 'wb') as f:
        pickle.dump(algo_output, f)
```
æœ€åï¼Œæˆ‘ä»¬å¯ä»¥è½»æ¾åœ°å¯è§†åŒ–æ¨ç†è¿‡ç¨‹ï¼š
```python
import pickle
from reasoners.visualization import visualize
with open("logs/bw_MCTS/xxx/algo_output/1.pkl", 'rb') as f:
    mcts_result = pickle.load(f)

from reasoners.visualization.tree_snapshot import NodeData, EdgeData # ä¿®æ­£ï¼šEdgeData ä¹Ÿéœ€è¦å¯¼å…¥
from reasoners.algorithm.mcts import MCTSNode

# é»˜è®¤æƒ…å†µä¸‹ï¼ŒçŠ¶æ€ä¼šä¸èŠ‚ç‚¹ä¸€èµ·æ˜¾ç¤ºï¼Œå¥–åŠ±ä»¥åŠåœ¨ `SearchConfig.reward` ä¸­ä¿å­˜çš„å­—å…¸ä¼šä¸è¾¹ä¸€èµ·æ˜¾ç¤ºã€‚
# æˆ‘ä»¬ä¹Ÿå¯ä»¥å®šä¹‰ä¸€ä¸ªè¾…åŠ©å‡½æ•°æ¥è‡ªå®šä¹‰æˆ‘ä»¬æƒ³åœ¨å¯è§†åŒ–å·¥å…·ä¸­çœ‹åˆ°çš„å†…å®¹ã€‚
def blocksworld_node_data_factory(n: MCTSNode) -> NodeData:
    return NodeData({"block state": n.state.blocks_state if n.state else None,
                     "satisfied": n.fast_reward_details if n.fast_reward_details else "Not expanded"})
def blocksworld_edge_data_factory(n: MCTSNode) -> EdgeData:
    # å‡è®¾ reward_details å­˜å‚¨åœ¨ MCTSNode çš„ reward_details å±æ€§ä¸­ï¼ˆæˆ–è€…é€šè¿‡å…¶ä»–æ–¹å¼è·å–ï¼‰
    # æ³¨æ„ï¼šåŸå§‹ä»£ç ç¤ºä¾‹ä¸­ MCTSNode æ²¡æœ‰ç›´æ¥å­˜å‚¨ reward_detailsï¼Œè¿™é‡Œå‡è®¾å¯ä»¥é€šè¿‡æŸç§æ–¹å¼è®¿é—®
    # å®é™…åº”ç”¨ä¸­å¯èƒ½éœ€è¦è°ƒæ•´ MCTS å®ç°æˆ–æ­¤å·¥å‚å‡½æ•°æ¥è®¿é—®æ‰€éœ€æ•°æ®
    reward_info = n.reward_details if hasattr(n, 'reward_details') else {} # å‡è®¾ reward_details å¯è®¿é—®
    intuition = reward_info.get('intuition', None) # ä» reward_details è·å– intuition
    return EdgeData({"reward": n.reward, "intuition": intuition})

visualize(mcts_result, node_data_factory=blocksworld_node_data_factory,
                       edge_data_factory=blocksworld_edge_data_factory)
```
ç„¶åä¼šå¼¹å‡ºä¸€ä¸ªå¯è§†åŒ–ç»“æœçš„ URLã€‚è¯¥å›¾å½¢å°†æ˜¯äº¤äº’å¼çš„ï¼Œçœ‹èµ·æ¥åƒæˆ‘ä»¬[æ¼”ç¤ºç½‘ç«™](https://llm-reasoners.net/)ä¸Šæ˜¾ç¤ºçš„ç¤ºä¾‹ã€‚
## å®‰è£…

è¯·ç¡®ä¿ä½¿ç”¨ Python 3.10 æˆ–æ›´é«˜ç‰ˆæœ¬ã€‚

```bash
conda create -n reasoners python=3.10
conda activate reasoners
```

### é€šè¿‡ `pip` å®‰è£…

```bash
pip install llm-reasoners
```

### ä» GitHub å®‰è£…
ï¼ˆæ¨èï¼Œå¦‚æœä½ æƒ³è¿è¡Œ GitHub ä»“åº“ä¸­çš„ç¤ºä¾‹ï¼‰

```bash
git clone https://github.com/Ber666/llm-reasoners --recursive
cd llm-reasoners
pip install -e .
```
æ·»åŠ  `--recursive` å‚æ•°ä¼šè‡ªåŠ¨å…‹éš† exllama å’Œ LLM-Planningã€‚è¯·æ³¨æ„ï¼ŒæŸäº›å¯é€‰æ¨¡å—å¯èƒ½éœ€è¦å…¶ä»–ä¾èµ–é¡¹ã€‚è¯¦æƒ…è¯·å‚è€ƒé”™è¯¯ä¿¡æ¯ã€‚

## å¼•ç”¨
æœ¬é¡¹ç›®æ˜¯ä»¥ä¸‹è®ºæ–‡çš„æ‰©å±•ï¼š
```bibtex
@inproceedings{hao2023reasoning,
  title={Reasoning with Language Model is Planning with World Model},
  author={Hao, Shibo and Gu, Yi and Ma, Haodi and Hong, Joshua and Wang, Zhen and Wang, Daisy and Hu, Zhiting},
  booktitle={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  pages={8154--8173},
  year={2023}
}
@article{hao2024llm,
  title={LLM Reasoners: New Evaluation, Library, and Analysis of Step-by-Step Reasoning with Large Language Models},
  author={Hao, Shibo and Gu, Yi and Luo, Haotian and Liu, Tianyang and Shao, Xiyan and Wang, Xinyuan and Xie, Shuhua and Ma, Haodi and Samavedhi, Adithya and Gao, Qiyue and others},
  journal={arXiv preprint arXiv:2404.05221},
  year={2024}
}
```